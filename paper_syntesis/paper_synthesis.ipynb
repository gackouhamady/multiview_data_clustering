{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0625d030",
   "metadata": {},
   "source": [
    "# Analyse de LMGEC\n",
    "\n",
    "> Article analys√© : **LMGEC: Simultaneous Linear Multi-view Attributed Graph Representation Learning and Clustering**, WSDM 2023.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Probl√©matique centrale  :  \n",
    "LMGEC r√©pond √† la probl√©matique suivante :\n",
    "‚ÄúComment apprendre des repr√©sentations partag√©es et effectuer un clustering efficace sur des graphes multi-vues attribu√©s, tout en garantissant simplicit√©, rapidit√©, et robustesse face √† l‚Äôh√©t√©rog√©n√©it√© des vues ?‚Äù\n",
    ">\n",
    "\n",
    "![Alt text](problem.png)\n",
    "\n",
    "\n",
    "## üìÖ 1. M√©thodologie : quel type de fusion ?\n",
    "\n",
    "LMGEC repose sur une **fusion lin√©aire pond√©e tardive** des vues. \n",
    "\n",
    "- Chaque vue est d'abord **filtr√©e localement** (1-hop) pour lisser les attributs : $$ H_v = S_v X_v $$\n",
    "- Une **pond√©ration adaptative** des vues est appliqu√©e via des poids $$ \\alpha_v $$, calcul√©s dynamiquement.\n",
    "- Les embeddings obtenus sont projet√©s et **fusionn√©s dans un espace commun** pour effectuer le clustering.\n",
    "\n",
    "> **Type de fusion :** tardive + pond√©ration adaptative (soft fusion)\n",
    "\n",
    "---\n",
    "\n",
    "## üîç 2. Hypoth√®ses sur les vues\n",
    "\n",
    "- ‚úÖ M√™mes n≈ìuds dans toutes les vues\n",
    "- ‚úÖ Vues potentiellement **tr√®s h√©t√©rog√®nes** (topologies ou attributs)\n",
    "- ‚ùå Pas de traitement sp√©cial des vues **manquantes** ou d√©salign√©es\n",
    "- ‚úÖ Le mod√®le peut att√©nuer les vues bruit√©es via la pond√©ration $$ \\alpha_v $$\n",
    "\n",
    "---\n",
    "\n",
    "## üìä 3. Mod√®les math√©matiques\n",
    "\n",
    "- **Filtrage de chaque vue :** $$ H_v = S_v X_v $$, o√π $$ S_v = \\tilde{D}^{-1} (\\tilde{A}_v) $$ avec self-loops.\n",
    "\n",
    "- **Objectif :**\n",
    "$$\n",
    "\\min_{G, F, W_1,\\dots,W_V} \\sum_{v=1}^{V} \\alpha_v \\| H_v - G F W_v^\\top \\|^2\n",
    "$$\n",
    "Avec :\n",
    "  - $ G \\in \\{0,1\\}^{n \\times k} $ : clustering (soft or hard)\n",
    "  - $ W_v \\in \\mathbb{R}^{d \\times f} $, $ W_v W_v^\\top = I $\n",
    "\n",
    "- **Pond√©ration des vues :**\n",
    "$$\n",
    "\\alpha_v = \\text{softmax}\\left(-\\frac{I_v}{\\tau}\\right), \\quad I_v = \\| H_v - G_v F_v \\|\n",
    "$$\n",
    "\n",
    "> Optimisation par **Bloc Coordinate Descent**\n",
    "\n",
    "> \n",
    "![Alt text](recon.png)\n",
    "---\n",
    "\n",
    "## üìà 4. Types de donn√©es utilis√©es\n",
    "\n",
    "- **Topologies diff√©rentes, m√™mes features :** ACM, DBLP, IMDB\n",
    "- **M√™mes topologies, features diff√©rentes :** Amazon Photos\n",
    "- **Topologies + features diff√©rentes :** Wiki\n",
    "\n",
    "> LMGEC couvre **tous les cas multi-vues usuels**\n",
    "> \n",
    "![Alt text](topo.png)\n",
    "---\n",
    "\n",
    "## üìä 5. M√©triques d‚Äô√©valuation\n",
    "\n",
    "Les performances sont mesur√©es avec 4 m√©triques standards en clustering :\n",
    "\n",
    "| M√©trique | Description |\n",
    "|----------|-------------|\n",
    "| **NMI** | Normalized Mutual Information |\n",
    "| **ARI** | Adjusted Rand Index |\n",
    "| **ACC** | Accuracy (appliqu√©e au clustering) |\n",
    "| **F1-score** | Pr√©cision + rappel |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# üìä M√©triques d‚Äô√©valuation pour le clustering non supervis√©\n",
    "\n",
    "Lorsque j‚Äô√©value un algorithme de clustering (comme LMGEC), je dois utiliser des m√©triques quantitatives pour mesurer √† quel point les clusters trouv√©s sont coh√©rents avec les classes r√©elles (si elles sont disponibles). Voici les principales m√©triques utilis√©es :\n",
    "\n",
    "---\n",
    "\n",
    "| **M√©trique** | **Nom complet** | **Ce qu‚Äôelle mesure** | **Valeurs typiques** |\n",
    "|--------------|------------------|------------------------|-----------------------|\n",
    "| **NMI** | Normalized Mutual Information | Le degr√© de similarit√© entre les clusters pr√©dits et les vraies classes, bas√© sur l‚Äôinformation partag√©e | Entre 0 (aucune info) et 1 (parfait) |\n",
    "| **ARI** | Adjusted Rand Index | √Ä quel point deux partitions (clusters vs classes) sont en accord, corrig√© pour le hasard | Entre -1 (pire que hasard) et 1 (parfait accord) |\n",
    "| **ACC** | Clustering Accuracy | Pourcentage d‚Äôexemples correctement class√©s, apr√®s r√©assignation optimale des labels | Entre 0 et 1 (ou 0% √† 100%) |\n",
    "| **F1-score** | F1 Measure (harmonique pr√©cision / rappel) | Moyenne harmonique entre la pr√©cision (exactitude des clusters) et le rappel (couverture des vraies classes) | Entre 0 et 1 |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† D√©tails compl√©mentaires\n",
    "\n",
    "### üîπ NMI (Normalized Mutual Information)\n",
    "- Formule :\n",
    "$$\n",
    "\\text{NMI}(Y, C) = \\frac{2 \\, I(Y; C)}{H(Y) + H(C)}\n",
    "$$\n",
    "avec \\( I(Y; C) \\) l'information mutuelle entre la partition vraie \\( Y \\) et pr√©dite \\( C \\).\n",
    "- Avantage : **invariante aux permutations de labels**.\n",
    "\n",
    "### üîπ ARI (Adjusted Rand Index)\n",
    "- Tient compte du **nombre de paires** correctement regroup√©es ou s√©par√©es.\n",
    "- Corrige le **Rand Index** pour compenser le regroupement al√©atoire.\n",
    "- Avantage : bonne robustesse m√™me avec des d√©s√©quilibres de classe.\n",
    "\n",
    "### üîπ ACC (Accuracy)\n",
    "- Mesure directe et intuitive.\n",
    "- Requiert une **permutation optimale des clusters** (car les labels peuvent √™tre invers√©s).\n",
    "\n",
    "### üîπ F1-score\n",
    "- Combine deux notions :\n",
    "  - **Pr√©cision** : parmi les √©l√©ments du cluster, combien sont bien class√©s ?\n",
    "  - **Rappel** : parmi les vrais √©l√©ments d‚Äôune classe, combien sont captur√©s ?\n",
    "- L‚Äô√©quilibre entre les deux est utile surtout pour les classes d√©s√©quilibr√©es.\n",
    "\n",
    "---\n",
    "\n",
    "> En r√©sum√© : utiliser plusieurs m√©triques permet d‚Äôavoir une vue plus compl√®te de la qualit√© du clustering. NMI et ARI sont les plus stables pour comparer les m√©thodes, tandis que ACC et F1 donnent une interpr√©tation plus intuitive des performances.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# üéØ Contribution originale et √©valuation critique de LMGEC\n",
    "\n",
    "## üß© Quelle est la **contribution originale** du papier ?\n",
    "\n",
    "L‚Äôarticle propose **LMGEC**, un mod√®le lin√©aire simple et efficace pour :\n",
    "\n",
    "- R√©aliser **simultan√©ment** l‚Äôapprentissage de repr√©sentation et le clustering sur des graphes multi-vues attribu√©s.\n",
    "- Offrir une **formulation unifi√©e** int√©grant :\n",
    "  - une √©tape de **propagation locale (1-hop)** par un filtre de graphe lin√©aire,\n",
    "  - un **m√©canisme de pond√©ration adaptative des vues** (softmax sur l‚Äôinertie),\n",
    "  - un objectif combin√© de **reconstruction + clustering**.\n",
    "- √ätre **g√©n√©rique**, applicable √† :\n",
    "  - plusieurs graphes avec une m√™me matrice de features,\n",
    "  - plusieurs matrices de features sur un seul graphe,\n",
    "  - ou un m√©lange des deux (cas du dataset Wiki).\n",
    "- √ätre **beaucoup plus rapide** que les mod√®les existants tout en offrant des performances comparables, voire meilleures.\n",
    "- Fournir une **analyse math√©matique et exp√©rimentale approfondie** ainsi que le **code open-source**.\n",
    "\n",
    "## ‚úÖ **Points forts** de LMGEC\n",
    "\n",
    "| Atout | D√©tail |\n",
    "|-------|--------|\n",
    "| ‚úÖ Simplicit√© | Formulation lin√©aire claire et interpr√©table |\n",
    "| ‚úÖ Efficacit√© | Temps d'entra√Ænement **jusqu'√† 10√ó plus rapide** que les m√©thodes GCN ou autoencoder |\n",
    "| ‚úÖ Robustesse | Capacit√© √† ignorer les vues peu informatives via le m√©canisme d'attention/inertie |\n",
    "| ‚úÖ G√©n√©ralit√© | Supporte diff√©rents types de graphes multi-vues sans contraintes |\n",
    "| ‚úÖ Formulation unifi√©e | Apprentissage de repr√©sentation + clustering dans un m√™me objectif |\n",
    "| ‚úÖ Reproductibilit√© | Code disponible en open-source et r√©sultats d√©taill√©s sur 5 benchmarks |\n",
    "\n",
    "## ‚ö†Ô∏è **Limites** de LMGEC\n",
    "\n",
    "| Limite | D√©tail |\n",
    "|--------|--------|\n",
    "| ‚ùå M√©thode lin√©aire | Ne capture pas les non-lin√©arit√©s complexes, contrairement aux mod√®les deep |\n",
    "| ‚ùå Pas de gestion des vues manquantes | Chaque vue est suppos√©e compl√®te et bien align√©e |\n",
    "| ‚ùå Risque de sur-lissage √©vit√© uniquement via un filtrage 1-hop | Ce choix reste rigide dans certains cas |\n",
    "| ‚ùå Pas de m√©canisme d'apprentissage end-to-end avec supervision √©ventuelle | Mod√®le strictement non supervis√© |\n",
    "| ‚ùå Pas de m√©canisme explicite de fusion dynamique | Le poids est fix√© apr√®s initialisation (pas appris pendant optimisation) |\n",
    "\n",
    "## üß† Conclusion\n",
    "LMGEC se positionne comme une **alternative simple, rapide et robuste** aux m√©thodes complexes bas√©es sur GCN ou autoencodeurs. Il est particuli√®rement pertinent dans des contextes contraints en ressources ou n√©cessitant une interpr√©tabilit√© forte.\n",
    "\n",
    "Cependant, pour des cas tr√®s non-lin√©aires ou avec des donn√©es partiellement align√©es, des m√©thodes plus expressives comme les mod√®les √† attention ou graph contrastif peuvent √™tre pr√©f√©r√©es.\n",
    "\n",
    "## üåê R√©capitulatif Synth√©tique\n",
    "\n",
    "| √âl√©ment | D√©scription |\n",
    "|--------|-------------|\n",
    "| **Fusion** | Tardive, lin√©aire, pond√©ration adaptative |\n",
    "| **Hypoth√®ses sur les vues** | M√™mes n≈ìuds, h√©t√©rog√©n√©it√© support√©e |\n",
    "| **Formulation** | Lin√©aire, objectif joint reconstruction + clustering |\n",
    "| **Donn√©es** | Multi-vues topologiques, attributaires ou mixtes |\n",
    "| **M√©triques** | NMI, ARI, ACC, F1 |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
